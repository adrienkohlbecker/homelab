# jinja2: lstrip_blocks: "True"
# overseerr.service #######################################################################
[Unit]
Description=overseerr
After=network-online.target
Wants=network-online.target
StartLimitInterval=600
StartLimitBurst=5
{% if zfs_root %}
After=zfs_mount_mnt_services.service zfs_mount_mnt_media.service  zfs_autosnapshot.target
Requires=zfs_mount_mnt_services.service zfs_mount_mnt_media.service
PartOf=zfs_autosnapshot.target
{% endif %}

[Service]
Environment=PODMAN_SYSTEMD_UNIT=%n
Restart=on-failure
Delegate=yes
TimeoutStartSec=120
TimeoutStopSec=30
RestartSec=5
Type=notify
NotifyAccess=all

ExecStartPre=/bin/rm -f %t/%n.ctr-id
ExecStart=/usr/bin/podman run \
    --cidfile=%t/%n.ctr-id \
    --cgroups=split \
    {# todo move this to healthy on later podman versions, and remove ExecStartPost #}
    --sdnotify=conmon \
    --detach \
    --replace \
    --rm \
    --name overseerr \
    --log-driver journald \
    --log-opt tag="overseerr" \
    --env PUID={{ overseerr_user.uid }} \
    --env PGID={{ ansible_facts.getent_group['media'][1] }} \
    --env TZ=Europe/Paris \
    --volume /mnt/services/overseerr:/config \
    --volume /mnt/media:/media \
    --publish 127.0.0.1:5055:5055/tcp \
    --health-cmd "curl --head --location --fail --silent --show-error --connect-timeout 1 --max-time 5 http://localhost:5055/api/v1/status > /dev/null" \
    --health-start-period "10s" \
    docker.io/linuxserver/overseerr:1.33.2
ExecStartPost=/usr/local/bin/wait_for_healthy_container %t/%n.ctr-id
ExecStop=/usr/bin/podman stop --ignore --cidfile=%t/%n.ctr-id --time 60
ExecStopPost=/usr/bin/podman rm --force --ignore --cidfile=%t/%n.ctr-id

[Install]
WantedBy=default.target
{% if zfs_root %}
WantedBy=zfs_autosnapshot.target
{% endif %}
