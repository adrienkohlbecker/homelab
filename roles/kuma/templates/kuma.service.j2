# jinja2: lstrip_blocks: "True"
# kuma.service #######################################################################
[Unit]
Description=kuma
After=network-online.target
Wants=network-online.target
StartLimitInterval=600
StartLimitBurst=3
{% if zfs_root %}
After=zfs_mount_mnt_services.service zfs_autosnapshot.target
Requires=zfs_mount_mnt_services.service
PartOf=zfs_autosnapshot.target
{% endif %}

[Service]
Environment=PODMAN_SYSTEMD_UNIT=%n
Restart=always
Delegate=yes
TimeoutSec=120
RestartSec=5
Type=notify
NotifyAccess=all
SyslogIdentifier=%N

ExecStartPre=/bin/rm -f %t/%n.ctr-id
ExecStart=/usr/bin/podman run \
    --cidfile=%t/%n.ctr-id \
    --cgroups=split \
    --sdnotify=healthy \
    --detach \
    --replace \
    --rm \
    --name kuma \
    --log-driver journald \
    --log-opt tag="kuma" \
    --volume /mnt/services/kuma:/app/data \
    --env PUID={{ kuma_user.uid }} \
    --env PGID={{ kuma_user.group }}  \
    --publish 127.0.0.1:3001:3001/tcp \
    --health-cmd "curl --head --request GET --location --fail --silent --show-error --connect-timeout 1 --max-time 5 -o /dev/null http://localhost:3001/" \
    --health-startup-cmd "curl --head --request GET --location --fail --silent --show-error --connect-timeout 1 --max-time 5 -o /dev/null http://localhost:3001/" \
    --health-startup-interval "1s" \
    --health-startup-timeout "5s" \
    --stop-timeout 120 \
    docker.io/louislam/uptime-kuma:1.23.13
ExecStop=/usr/bin/podman stop --ignore --cidfile=%t/%n.ctr-id
ExecStopPost=/usr/bin/podman rm --force --ignore --cidfile=%t/%n.ctr-id

[Install]
WantedBy=default.target
{% if zfs_root %}
WantedBy=zfs_autosnapshot.target
{% endif %}
